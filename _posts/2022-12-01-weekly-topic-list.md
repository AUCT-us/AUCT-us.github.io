---
layout: post
title:  "Future Topics List"
date:   2022-12-01 4:30:00
categories: template
---


We mostly read as a break from work ... but we try to speedread *with serious, critical intention.* 

# Topic Lists

Our aim with this listing is to never have to think about our next list of items to read/annotate ... we want to have at least 125 good topic ideas in the hopper, to have 25 that we work on at least once a month, to have five that we touch once a week and to have ONE main one that we are focusing on getting right.

1) Microscopy, lithography, computational lithography

2) Atomic layer deposition, atomic layer etching, atomic layer epitaxy

3) Semiconductor manufacturing, semiconductor physics, semiconductor devices

4) Flowering plants, particularly trees, woody plants, shrubs, vines

5) Yoga, kinesiology, martial arts, self-defense

6) Sculpture, particularly optimal landsculpting, particularly parks and green spaces

7) Prayer, lojong meditation 

8) Podcastering, DAWs, audio engineering, Canva, GIMP, Inkscape, Blender

9) Python, python community, developer ecosystems

10) Unix, Linux, Containers, Virtual Machines, Operating Systems

11) Physics, quantum physics, quantum computing

12) Mathematics, especially geometric math, cuLitho, computational lithography

13) Chemistry, computational chemistry, computational materials science

14) Meta Open Access, beyond Wikipedia, peer review and wikiculture

15) TRIZ, ARIZ, technical knowledge-graph problem-solving, invention suggestions based on corpus of patents

16) Music, Music AI, Music Metadata

17) Ollam.ai and alternatives for natural language processing tasks such as: spaCY, NLTK, TextBlob, TensorFlow, HuggingFace Transformers, Amazon Comprehend, Google Cloud Natural Language API

18) Mark builds, uses and refines [his new AI applications which are built with AI](https://partyrock.aws/u/MarkBruns/IKKJt96W8/Daily-Wellness-Guide)

19) Future HEDT sandbox configuration: HBM3 GPU memory, DDR5 memory, NVME flash drives for High-Throughput Generative Inference for LLMs with Multiples GPUs ... the [secret sauce is PagedAttention](https://blog.vllm.ai/2023/06/20/vllm.html)

20) [JAX](https://jax.readthedocs.io/en/latest/notebooks/quickstart.html) is NumPy on the CPU, GPU, and TPU, with great automatic differentiation for high-performance machine learning research. What’s new is that JAX uses [XLA(the Accelerated Linear Algebra compiler)](https://www.tensorflow.org/xla) to compile and run your NumPy code on accelerators, like GPUs and TPUs.

21) [WasmEdge](https://wasmedge.org/docs/) and [TinyLlama](https://github.com/jzhang38/TinyLlama) ... including the use of [crun](https://github.com/containers/crun), [youki](https://github.com/containers/youki), [gVisor](https://gvisor.dev/), [Kata Containers](https://katacontainers.io/) and similar approaches to achieve faster, more secure, smaller footprint, lower-memory requirement [OCI Runtime](https://opencontainers.org/posts/blog/2023-07-21-oci-runtime-spec-v1-1/) containerized resources for edge computing.

22) [The last week or so's worth of Arxiv pre-print abstracts in Machine Learning](https://arxiv.org/search/advanced?advanced=&terms-0-operator=AND&terms-0-term=cs.LG&terms-0-field=all&terms-1-operator=AND&terms-1-term=&terms-1-field=title&classification-physics_archives=all&classification-include_cross_list=include&date-filter_by=past_12&date-year=&date-from_date=&date-to_date=&date-date_type=submitted_date&abstracts=show&size=200&order=-announced_date_first) ... the current rate of new papers is about 42,000 per year or 800 per week.

23) [Methods of information geometry](https://www.ams.org/books/mmono/191/mmono191-endmatter.pdf) including things lie the [Fisher information](https://en.wikipedia.org/wiki/Fisher_information) carried in an observable random variable about an unknown parameter and how the [Cramér–Rao bound(CRB)](https://en.wikipedia.org/wiki/Cram%C3%A9r%E2%80%93Rao_bound) or the [Hammersley-Chapman–Robbins lower bound](https://en.wikipedia.org/wiki/Chapman%E2%80%93Robbins_bound) used to bound the variance of biased estimators of a given biased.

24) [The last week or so's worth of Arxiv preprint abstracts on Condensed Matter Physics](https://arxiv.org/search/advanced?advanced=&terms-0-operator=AND&terms-0-term=phase+transitions&terms-0-field=title&classification-physics=y&classification-physics_archives=cond-mat&classification-include_cross_list=include&date-filter_by=past_12&date-year=&date-from_date=&date-to_date=&date-date_type=submitted_date&abstracts=show&size=200&order=-announced_date_first) with an emphasis on [phase transitions](https://en.wikipedia.org/wiki/Phase_transition) and a particular emphasis on [geometric frustration](https://arxiv.org/search/advanced?advanced=&terms-0-operator=AND&terms-0-term=geometrical+frustration&terms-0-field=title&classification-physics=y&classification-physics_archives=cond-mat&classification-include_cross_list=include&date-filter_by=all_dates&date-year=&date-from_date=&date-to_date=&date-date_type=submitted_date&abstracts=show&size=200&order=-announced_date_first)

25) The [pattern of frustration formation in the functional brain network](https://direct.mit.edu/netn/article/6/4/1334/112207/Pattern-of-frustration-formation-in-the-functional) and our [requirement to change of functional brain network across the lifespan](https://pubmed.ncbi.nlm.nih.gov/34793536/) and the [dynamics of the process of cognitive dissonance removal](https://www.connectedpapers.com/main/40acbf791850dc0fc1a2ff04670ef86e20ee95a8/Lifetime-of-links-influences-the-evolution-towards-structural-balance/graph), ie "How can we learn faster?".

26)

27)

28)

29)

30)

31)

32) 

33)

34) 

35)

36)

37)

38)

39)

40)

41)

42) 

43)

44) 

45)

46)

47)

48)

49)

50)

51)

52) 

53)

54) 

55)

56)

57)

58)

59)

60)

61)

62) 

63)

64) 

65)

66)

67)

68)

69)

70)

71)

72) 

73)

74) 

75)

76)

77)

78)

79)

80)

81)

82) 

83)

84) 

85)

86)

87)

88)

89)

90)

91)

92) 

93)

94) 

95)

96)

97)

98)

99)

100)

101)

102) 

103)

104) 

105)

106)

107)

108)

109)

110)

111)

112) 

113)

114) 

115)

116)

117)

118)

119)

120)

121)

122)

123)

124)

125)

# Exploratory / Wild Brainstorm Lists ... *which might become reading lists*


* 

* 

* 

* 
